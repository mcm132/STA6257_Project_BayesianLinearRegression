---
title: "Data Science Capstone Project Spring 2024 - Bayesian Linear Regression"
author: "Mary Catherine Morrow"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction

### What is "Bayesian Linear Regression"?

This is an introduction to Bayesian Linear Regression, which is a ...

### Article 1 from Week 2:

**Title:** Bayesian multivariate linear regression with application to
change point models in hydrometeorological variables

**Summary:** The article cited first discusses the history of Bayesian
analysis, including the definition, and how it relates to climate
change. It then dives into three different Bayesian change point
detection models (Perreault et al. \[2000a\], Perreault et al.
\[2000b\], and Rasmussen \[2001\]) and how they compare against Bayesian
analysis paired with Gibbs sampling. By comparing against these three
models, the proposed method “can readily be applied to cases where the
change point simultaneously occurs in several response variables, to
cases where the change does not occur with certainty and to cases where
informative priors are appropriate”. [@seidou2007]

**Citation:** O. Seidou, J. Asselin, and T. B. M. J. Ouarda, “Bayesian
multivariate linear regression with application to change point models
in hydrometeorological variables,” Water Resources Research, vol. 43,
no. 8, Aug. 2007, doi: 10.1029/2005wr004835.

### Article 2 from Week 2:

**Title:** Positional error compensation for aviation drilling robot
based on Bayesian linear regression

**Summary:** The article cited discusses how Bayeisan Linear Regression
was used to model positional accuracy of aviation drilling robots using
a training data set. After the model was built, experiments were
performed to confirm the model’s functionality, where a test dataset was
used. The experiements showed that using this method to model the
positional accuracy resulted in being within the 95% confidence interval
and a high R2 value of 0.941, meaning the Bayesian Linear Regression
method has good compensation performance for aviation
drilling.[@chen2024]

**Citation:** D. Chen, P. Lv, L. Xue, H. Xing, L. Lu, and D. Kong,
“Positional error compensation for aviation drilling robot based on
Bayesian linear regression,” Engineering Applications of Artificial
Intelligence, vol. 127, p. 107263, Jan. 2024, doi:
10.1016/j.engappai.2023.107263.

### Article 1 from Week 3:

**Title:** Evidence for a non-universal Kennicutt-Schmidt relationship
using hierarchical Bayesian linear Regression

**Summary:** The goal of the research described in the article cited was
to create a model, particularly a Bayesian Linear Regression (BLR)
model, that estimated the parameters of the Kennicutt-Schmidt (KS) law
and the hierarchal structure of a given data set. The BLR model was
constructed using Markov Chain Monte Carlo (MCMC) and Gibb’s sampling.
The model was tested with synthetic test data sets made to match the
format of the model building data set. The model was considered to have
a high degree of accuracy by comparing median of the posterior, the
posterior distributions of the slope and intercept, the median of the
scatter term, and PDFs of the estimated group parameters against the
true values. Then, the Bayesian model was compared to the Ordinary Least
Squares (OLS) model for an accuracy check. Here, the OLS model
consistently overestimated the slopes and underestimated the intercepts
for individual galaxies within the group as well as the group as a
whole. This was expected as the data set included noise and scatter,
which are not accounted for in the OLS method. By testing distribution
hypotheses using the OLS method and comparing it against the Bayesian
method, it was shown that Bayesian posterior can recover individuals’
slopes and intercepts regardless if the assumed distribution is
incorrect. However, accuracy of the Bayesian method increases if the
correct distribution assumptions are made. [@shetty2013]

**Citation:** R. Shetty, B. C. Kelly, and F. Bigiel, “Evidence for a
non-universal Kennicutt–Schmidt relationship using hierarchical Bayesian
linear regression,” Monthly Notices of the Royal Astronomical Society,
vol. 430, no. 1, pp. 288–304, Jan. 2013, doi: 10.1093/mnras/sts617.

### Article 2 from Week 3:

**Title:** Bayesian linear regression with sparse priors

**Summary:** This cited article details the Bayesian method for
high-dimensional linear regression under sparsity constraints. A
standard model was used, but it focused mainly on the sparse setup,
where n is less than or greater than p and many of the coefficients of
the parameter vector are zero, or close there to. Within the work, it is
shown that the LASSO frequentist method is non-Bayesian. [@castillo2015]

**Citation:** I. Castillo, J. Schmidt-Hieber, and A. Van Der Vaart,
“Bayesian linear regression with sparse priors,” The Annals of
Statistics, vol. 43, no. 5, Oct. 2015, doi: 10.1214/15-aos1334.

### Article 1 from Week 4:

**Title:** How to lose at Monte Carlo: a simple dynamical system whose
typical statistical behavior is non-computable

**Summary:** This cited article expands upon the idea of using
statistical predictions, with the Monte Carlo method , to make “future
behavior of nonlinear dynamical systems”, and aimed to find where the
Monte Carlo method fails. This is important because it helps further
define the limitations of the method, which allows for more proper use
of the method in the future. Through the analysis, the Monte Carlo
method was deemed to not work through the use of non-computable physical
measures, like a black-box. [@rojas2020]

**Citation:** C. Rojas and M. Yampolsky, “How to lose at Monte Carlo: a simple dynamical system whose typical statistical behavior is non-computable,”Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, pp. 1066–1072, Jun. 2020, doi: 10.1145/3357713.3384237.

### Article 2 from Week 4:

**Title:** Gibbs sampling on large lattice with GMRF

**Summary:** The goal of the cited article was to construct a method for using Gibbs sampling for large lattices, which includes greater than 100 points. This is helpful as it allows for Gibbs sampling to be applied to 2D and 3D lattice structures using GMRF (Gaussian Markov Random Fields) covariance. This article gives good applications of GMRF, Gibbs sampling, and Gibbs sampling with GMRF.[@marcotte2018]

**Citation:** D. Marcotte and D. Allard, “Gibbs sampling on large lattice with GMRF,” Computers & Geosciences, vol. 111, Art. no. 190, Feb. 2018, doi: 10.1016/j.cageo.2017.11.012.

## Methods

To be updated at a later date.

## Analysis and Results

### Data and Visualization

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Statistical Modeling

```{r}

```

### Conclusion

## References
